---
title: "p8130_final_project"
author: "Qinyao Wu"
date: "12/6/2018"
output: github_document
---

```{r setup, include=FALSE}

#Install the packges.

knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(faraway)
library(leaps)
library(caret)
library(boot)
library(broom)
library(modelr)
library(parcor)
library(MASS)
library(glmnet)
library(reshape2)
```

```{r import_data}
#Import data
cancer_data = read_csv("./data/Cancer_Registry.csv") 
 
#Count na, modify the na table to show the variable with NAs. 
cancer_na = map_df(cancer_data, function(x) sum(is.na(x))) %>% data.frame() %>%
  t() %>% data.frame()

#Add column names.
colnames(cancer_na) = "na_counts"

#Make a table for na. 
cancer_na = cancer_na %>% mutate(variable_name = row.names(cancer_na)) %>% dplyr::select(2, 1) %>%
  filter(na_counts > 0) %>% knitr::kable()
cancer_na

```

```{r}
#Tidy the data set. 
cancer_data_analysis = cancer_data %>% 
  janitor::clean_names() %>% 

  #Make income a dummy variable by divide up by mean of income. 
  mutate(med_income = as.numeric(med_income) ) %>% 
  mutate(income_cat = ifelse(med_income >= mean(med_income), 1, 0)) %>% 
  
  #Divide up ages by mean of age. 
  mutate(age_cat = ifelse(median_age >= mean(median_age), 1, 0)) %>%
  
  #remove variables with a lot of na, pct_employed16_over do not have a lot, so we decide to keep it. 
  dplyr::select(-pct_some_col18_24, -pct_private_coverage_alone, -med_income) %>% 
  
  #remove unrelated variables
  dplyr::select(-binned_inc, -pct_employed16_over) %>% 
 
  #Make the y at the first column. 
  dplyr::select(target_death_rate, everything())
  
 #Skim over all the variables.  
cancer_data_analysis %>% 
  dplyr::select(-geography) %>% 

 skimr::skim()

#Look at the overall correlation. 
cancer_data_analysis %>% 
  dplyr::select(-geography) %>% 
  cor() %>% 
  knitr::kable()

summary(cancer_data_analysis)
```


```{r}
#Choose variables we are interested in and the variables from primary literature.  
#Reasons for choosing these variables:
# compared the employed status
# compare the education status
# white has the largest percentage, so we decide to choose white.
cancer_s = cancer_data_analysis %>%
  dplyr::select(target_death_rate, avg_ann_count, incidence_rate, pct_unemployed16_over, age_cat, pct_private_coverage, pct_white, pct_hs25_over, pct_hs18_24, geography, income_cat, study_per_cap)
rownames(cancer_s) = cancer_s$geography
cancer_s = cancer_s %>% 
  dplyr::select(-geography)
#Look at the covariance between the variables. 
cor(cancer_s) %>% knitr::kable()
#Look at the overall distribution and percentiles of the variables we choose.
skimr::skim(cancer_s)
cancer_s %>% 
  ggplot(aes(x = target_death_rate)) + 
    geom_histogram(aes(y = ..density..),  
                   binwidth = 2, colour = "black", fill = "white") +
    geom_density(alpha = .1) +
    labs(title = "Distribution of target death")
#Make a histogram set to show the normal distribution of the variables to decide whether transformation is required. 
cancer_s %>%
  dplyr::select(-age_cat) %>%
  gather(measure, value) %>%
  ggplot(aes(value)) +
  facet_wrap(. ~ measure, scales = "free") +
  geom_histogram()
#Find the significant variables in each number of parameters. Used as a reference for later removal of variables. 
criterion_subset = regsubsets(target_death_rate ~ ., data = cancer_s, nvmax = 34)
   (rs = summary(criterion_subset))
par(mar = c(4,4,1,1))
par(mfrow = c(1,2))
## Only 8ï¼Œ 9 and 10 variables have a cp smaller or equal to the number of parameter. And between these two, 8-variable model has a smaller cp, as a result, we decide to choose the 8-varable model which is the model without study per cap. Since income_cat is correlated to both unemployment and health insurance coverage, it is removed too. 


plot(2:11, rs$cp, xlab = "No of parameters", ylab = "Cp Statistic")
abline(0,1)
 
plot(2:11, rs$adjr2, xlab = "No of parameters", ylab = "Adj R2")



#So we decide this is our final model. 

cancer_s = cancer_s %>% 
  dplyr::select(-study_per_cap, -income_cat)

cancer_lm = lm(target_death_rate ~ ., data = cancer_s)
summary(cancer_lm)

```


###Model Diagnostic

```{r}
#Add the row names for the data set using the geography column. 
#Apply the model we built. 
cancer_lm = lm(target_death_rate ~ ., data = cancer_s)

## outlier in Y-Look at the studendized ourliers
stu_res = rstandard(cancer_lm)
outliers_y = stu_res[abs(stu_res) > 2.5]
count(as.data.frame(outliers_y))

#Make four plots to show whether the assumptions are met. 
par(mfrow = c(2,2))
plot(cancer_lm)

# 1000 might be an influential outlier. 
lev = hatvalues(cancer_lm)
lev[lev > 0.2]

#a = cancer_data_analysis[-1000,]

#Calculate the DIFFITS to determine the outliers. 
diffits_data = dffits(cancer_lm) %>%
  data.frame()

colnames(diffits_data) = c("diffit")

diffits_outlier = diffits_data %>%
  filter(diffit > 2*sqrt(8/3047))

#not influential outlier change in coef < 6%---decide to keep all obes
cancer_s %>% 
  filter(!(row.names(cancer_s) %in% c("Williamsburg city, Virginia", "Madison County, Mississippi", "Woodson County, Kansas", "Aleutians West Census Area, Alaska", "Los Angeles County, California"))) %>% 
  lm(target_death_rate ~ ., data=.) %>% 
  summary()
```

# Cross-Validation

```{r}

# CV for our selected variables
data_train = trainControl(method = "repeatedcv", number = 10, repeats = 10)
# Fit the 4-variables model that we discussed in previous lectures
model_caret <- train(target_death_rate ~ avg_ann_count + incidence_rate + pct_unemployed16_over + age_cat + pct_private_coverage + pct_white + pct_hs25_over + pct_hs18_24, data = cancer_data_analysis,
                   trControl=data_train,
                   method='lm',
                   na.action=na.pass)
model_caret

# CV for more variables (including unselected)
data_train_2 = trainControl(method = "repeatedcv", number = 10, repeats = 10)
model_caret_2 = train(target_death_rate ~ incidence_rate + poverty_percent + median_age_female 
                    + percent_married + pct_hs18_24 + pct_hs25_over + pct_bach_deg25_over 
                    + pct_unemployed16_over + pct_private_coverage + pct_emp_priv_coverage 
                    + pct_public_coverage + pct_white + pct_black + pct_other_race + birth_rate, 
                    data = cancer_data_analysis,
                    trControl=data_train_2,
                    method='lm',
                    na.action=na.pass)

RMSE = mean(model_caret_2$resample$RMSE)
RMSE
```

# Bootstrap
 
```{r bootstrap}
boot.fn<-function(data, index){
	return(coef(lm(target_death_rate ~ ., data = data, subset=index)))
}

results = boot(cancer_s, boot.fn, 10000)
rmse(cancer_lm, cancer_s)
plot(results, index = 1)
#results$t[ ,1]

#results_raw = boot(cancer_data_analysis, boot.fn, 10000)
#cancer_overall = lm(target_death_rate ~ ., data = cancer_data_analysis)
#rmse(cancer_overall, cancer_data_analysis)
#plot(results_raw, index = 1)
```


## Lasso Model Selection
```{r}
cancer_data_lasso = 
  cancer_data_analysis %>% 
  dplyr::select(-geography)

# Lasso on all variables
set.seed(1)
Y <- cancer_data_lasso$target_death_rate
X <- model.matrix(~., data = cancer_data_lasso[,-1])
train <- sample(1:nrow(X), nrow(X)/2)
grid <- 10^seq(5, -2, length = 100)
cv.out <- cv.glmnet(X[train,],Y[train]) # all possible lambda values
plot(cv.out) # CV process
cv.out$lambda.min
lasso_haha = glmnet(X, Y, alpha = 1, lambda = cv.out$lambda.min)
coef(lasso_haha) # fitting with chosen lambda
lasso_haha$dev.ratio

# Lasso on selected variables
Y1 <- cancer_s$target_death_rate
X1 <- model.matrix(~., data = cancer_s[,-1])
train <- sample(1:nrow(X1), nrow(X1)/2)
grid <- 10^seq(5, -2, length = 100)
cv.out <- cv.glmnet(X1[train,],Y1[train]) # all possible lambda values
plot(cv.out) # CV process
cv.out$lambda.min
lasso_haha = glmnet(X1, Y1, alpha = 1, lambda = cv.out$lambda.min)
coef(lasso_haha) # fitting with chosen lambda
lasso_haha$dev.ratio
```


```{r ridge&lasso}
# Try a grid of values for lambda: from 10^-2 to 10^5
grid <- 10^seq(5,-2, length=100)

c_lasso = as.data.frame(cancer_data_lasso)
Y <- c_lasso[,1]
X <- as.matrix(c_lasso[,-1])

set.seed(1)
train<-sample(1:nrow(X),nrow(X)/2)
test<-(-train)
Y.test<-Y[test]

# Cross-validation
set.seed(2)
cv.out<-cv.glmnet(X[train,],Y[train], alpha=1)
coef(cv.out)
plot(cv.out)

best.lambda<-cv.out$lambda.min
best.lambda

# Fit a Lasso model with all observations with the best lambda
lasso2 <- glmnet(X, Y, alpha = 1, lambda=best.lambda)
coef(lasso2)
lasso2$dev.ratio

# Fit a Lasso model with all observations with the best lambda grid.
lasso3 <- glmnet(X, Y, alpha = 1, lambda=grid)

# Save the estimated 'standardized' coefficients for all 7 predictors without the intercept that is not of interest.
coef_lasso3 <- coef(lasso3)[-1,]
coef_lasso3_mat <- t(as.matrix(coef_lasso3))
rownames(coef_lasso3_mat) <- grid
coef_lasso3_mat_sort <- coef_lasso3_mat[order(grid),]
par(mfrow = c(1,1))
matplot(coef_lasso3_mat_sort,type="l",lty=1,xlim=c(0,50),
        xlab="lambda",ylab="coefficient",col=1:29) 
legend('bottomright', inset=.005, legend=colnames(coef_lasso3_mat_sort), 
       pch=4, cex=0.4, col=1:29)

lasso3 <- glmnet(X,Y, alpha=1, lambda=grid)


fit = cv.glmnet(X, Y)
plot(fit,label = TRUE)
coef(fit,s=cv.out$lambda.1se)
```

