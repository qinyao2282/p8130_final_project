---
title: "p8130_final_project"
author: "Qinyao Wu"
date: "12/6/2018"
output: html_document
---

```{r setup, include=FALSE}

#Install the packges.

knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(faraway)
library(leaps)
library(caret)
library(boot)
library(broom)
library(modelr)
```

```{r import_data}
#Import data
cancer_data = read_csv("./data/Cancer_Registry.csv") 
 
#Count na, modify the na table to show the variable with NAs. 
cancer_na = map_df(cancer_data, function(x) sum(is.na(x))) %>% data.frame() %>%
  t() %>% data.frame()

#Add column names.
colnames(cancer_na) = "na_counts"

#Make a table for na. 
cancer_na = cancer_na %>% mutate(variable_name = row.names(cancer_na)) %>% dplyr::select(2, 1) %>%
  filter(na_counts > 0) %>% knitr::kable()
cancer_na

```

```{r}
#Tidy the data set. 
cancer_data_analysis = cancer_data %>% 
  janitor::clean_names() %>% 

  #Make income a dummy variable by divide up by mean of income. 
  mutate(med_income = as.numeric(med_income) ) %>% 
  mutate(income_cat = ifelse(med_income >= mean(med_income), 1, 0)) %>% 
  
  #Divide up ages by mean of age. 
  mutate(age_cat = ifelse(median_age >= mean(median_age), 1, 0)) %>%
  
  #remove variables with a lot of na, pct_employed16_over do not have a lot, so we decide to keep it. 
  dplyr::select(-pct_some_col18_24, -pct_private_coverage_alone, -med_income) %>% 
  
  #remove unrelated variables
  dplyr::select(-binned_inc) %>% 
 
  #Make the y at the first column. 
  dplyr::select(target_death_rate, everything())
  
 #Skim over all the variables.  
cancer_data_analysis %>% 
  dplyr::select(-geography) %>% 

 skimr::skim()

#Look at the overall correlation. 
cancer_data_analysis %>% 
  dplyr::select(-geography) %>% 
  cor() %>% 
  knitr::kable()

summary(cancer_data_analysis)
```


```{r}
#Choose variables we are interested in and the variables from primary literature.  

#Reasons for choosing these variables:

# compared the employed status
# compare the education status
# white has the largest percentage, so we decide to choose white.

cancer_s = cancer_data_analysis %>%
  dplyr::select(target_death_rate, avg_ann_count, incidence_rate, pct_unemployed16_over, age_cat, pct_private_coverage, pct_white, pct_hs25_over, pct_hs18_24, geography)

rownames(cancer_s) = cancer_s$geography

cancer_s = cancer_s %>% 
  select(-geography)

#Look at the covariance between the variables. 
cor(cancer_s) %>% knitr::kable()

#Look at the overall distribution and percentiles of the variables we choose.
skimr::skim(cancer_s)

cancer_s %>% 
  ggplot(aes(x = target_death_rate)) + 
    geom_histogram(aes(y = ..density..),  
                   binwidth = 2, colour = "black", fill = "white") +
    geom_density(alpha = .1) +
    labs(title = "Distribution of target death")

#Make a histogram set to show the normal distribution of the variables to decide whether transformation is required. 
cancer_s %>%
  dplyr::select(-age_cat) %>%
  gather(measure, value) %>%
  ggplot(aes(value)) +
  facet_wrap(. ~ measure, scales = "free") +
  geom_histogram()


#Find the significant variables in each number of parameters. Used as a reference for later removal of variables. 
criterion_subset = regsubsets(target_death_rate ~ ., data = cancer_s, nvmax = 34)
   (rs = summary(criterion_subset))

par(mar = c(4,4,1,1))
par(mfrow = c(1,2))

#Only when the p equals to 9, Cp=8.76 < Parameter. As a result, we decide that the number of predictors would be 9-1 = 8 or 10-1 = 9. So we look back to the significance table and we found that only the study_per_cap is not significant and we decided to remove it. 

plot(2:9, rs$cp, xlab = "No of parameters", ylab = "Cp Statistic")
abline(0,1)

#And at parameter equals to 9, the adjusted r square value is highest. 
plot(2:9, rs$adjr2, xlab = "No of parameters", ylab = "Adj R2")

#So we decide this is our final model. 
cancer_lm = lm(target_death_rate ~ ., data = cancer_s)
summary(cancer_lm)
```


###Model Diagnostic

```{r}
#Add the row names for the data set using the geography column. 
#Apply the model we built. 
cancer_lm = lm(target_death_rate ~ ., data = cancer_s)

## outlier in Y-Look at the studendized ourliers
stu_res = rstandard(cancer_lm)
outliers_y = stu_res[abs(stu_res) > 2.5]

#Make four plots to show whether the assumptions are met. 
par(mfrow = c(2,2))
plot(cancer_lm)

# 1000 might be an influential outlier. 
lev = hatvalues(cancer_lm)
lev[lev > 0.2]

#a = cancer_data_analysis[-1000,]

#Calculate the DIFFITS to determine the outliers. 
diffits_data = dffits(cancer_lm) %>%
  data.frame()

colnames(diffits_data) = c("diffit")

diffits_outlier = diffits_data %>%
  filter(diffit > 2*sqrt(8/3047))

#not influential outlier change in coef < 6%---decide to keep all obes
cancer_s %>% 
  filter(!(row.names(cancer_s) %in% c("Williamsburg city, Virginia", "Madison County, Mississippi", "Woodson County, Kansas", "Aleutians West Census Area, Alaska", "Los Angeles County, California"))) %>% 
  lm(target_death_rate ~ ., data=.) %>% 
  summary()
```

# Cross-Validation

```{r}

# CV for our selected variables
data_train = trainControl(method = "repeatedcv", number = 10, repeats = 10)
# Fit the 4-variables model that we discussed in previous lectures
model_caret <- train(target_death_rate ~ avg_ann_count + incidence_rate + pct_unemployed16_over + age_cat + pct_private_coverage + pct_white + pct_hs25_over + pct_hs18_24, data = cancer_data_analysis,
                   trControl=data_train,
                   method='lm',
                   na.action=na.pass)
model_caret

# CV for more variables (including unselected)
data_train_2 = trainControl(method = "repeatedcv", number = 10, repeats = 10)
model_caret_2 = train(target_death_rate ~ incidence_rate + poverty_percent + median_age_female 
                    + percent_married + pct_hs18_24 + pct_hs25_over + pct_bach_deg25_over 
                    + pct_unemployed16_over + pct_private_coverage + pct_emp_priv_coverage 
                    + pct_public_coverage + pct_white + pct_black + pct_other_race + birth_rate, 
                    data = cancer_data_analysis,
                    trControl=data_train_2,
                    method='lm',
                    na.action=na.pass)

RMSE = mean(model_caret_2$resample$RMSE)
RMSE
```

# Bootstrap
 
```{r bootstrap}
boot.fn<-function(data, index){
	return(coef(lm(target_death_rate ~ ., data = data, subset=index)))
}

results = boot(cancer_s, boot.fn, 10000)
rmse(cancer_lm, cancer_s)
plot(results, index = 1)
results$t[ ,1]

#results_raw = boot(cancer_data_analysis, boot.fn, 10000)
#cancer_overall = lm(target_death_rate ~ ., data = cancer_data_analysis)
#rmse(cancer_overall, cancer_data_analysis)
#plot(results_raw, index = 1)
```

```{r ridge&lasso}
#install.packages("parcor")
library(parcor)
library(MASS)
library(glmnet)
library(reshape2)

# Start with the full model
mult.fit <- lm(target_death_rate ~ ., data=cancer_s)
summary(mult.fit)

#Ridge Regression
ridge1 <- lm.ridge(target_death_rate ~., data=cancer_s)
ridge1

# Compare the LS and Ridge coefficients.
# No difference because the default value for lambda (tunning parameter) is set to 0 by default.
coef(ridge1)
coef(mult.fit)

# Try a grid of values for lambda: from 10^-2 to 10^5

grid <- 10^seq(5,-2, length=100)


# Matrix of 100X8 containing coefficients for all 100 values of lambda
ridge2 <- lm.ridge(target_death_rate ~., data=cancer_s, lambda=grid)
dim(coef(ridge2))

######################################################
#            Use function glmnet()                   #
######################################################

cancer_df = data.frame(cancer_s)
Y <- cancer_df[,1]
X <- as.matrix(cancer_df[,-1])

# Penalty term: alpha; Ridge alpha=0 (default); Lasso alpha=1 (default)
ridge3<-glmnet(X, Y, alpha = 0, lambda = grid)
dim(coef(ridge3))

# Look at lambda and the coeff estimates on position 50
ridge3$lambda[50]
coef(ridge3)[,50]

# L2 norm for Ridge
# sqrt(sum(coef(ridge3)[-1,50]^2))
#Choice of lambda: Cross Validation (CV)
# Choose the training sample: 50:50

set.seed(1)
train<-sample(1:nrow(X),nrow(X)/2)
test<-(-train)
Y.test<-Y[test]

# Use build-in CV function; performs a 10-fold validation by default
# glmnet() generates it's own lambda sequence

set.seed(2)
cv.out<-cv.glmnet(X[train,],Y[train], alpha=0)
plot(cv.out)

# cv.glmnet() object contains the mean cross-validation error (cvm),
# lambda min that gives the minimum cvm, etc.
cv.out
best.lambda<-cv.out$lambda.min
best.lambda

# Re-fit the model with the min lambda value, look at the coeff and MSE
#ridge.pred <- predict(ridge.cv(), s = best.lambda, newx = X[test,])

#mean((ridge.pred-Y.test)^2)

# Ridge regression using all observations and 'best' lambda
ridge3<-glmnet(X, Y, alpha=0, lambda=best.lambda)
res_ridge_ls<- cbind(coef(mult.fit),coef(ridge3))
colnames(res_ridge_ls) <- c("LS", "Ridge")
res_ridge_ls

#Lasso regression
lasso1<- glmnet(X[train ,],Y[train], alpha =1, lambda=grid)


# Cross-validation
set.seed(2)
cv.out<-cv.glmnet(X[train,],Y[train])
plot(cv.out)

best.lambda<-cv.out$lambda.min

#lasso.pred=predict(lasso1,s=best.lambda,newx=X[test,])
#mean((lasso.pred-Y.test)^2)

# Fit a Lasso model with all observations with the best lambda
lasso2<- glmnet(X, Y, alpha =1, lambda=best.lambda)
coef(lasso2)
coef(mult.fit)

# Fraction of deviance explained
# Similar interpretation to R-squared: % variance explained by non-zero variables variables
lasso2$dev.ratio

# Compare LS, Ridge and Lasso regression coefficients
res_ls_ridge_lasso<- cbind(coef(mult.fit),coef(ridge3),coef(lasso2))
colnames(res_ls_ridge_lasso) <- c("LS", "Ridge","Lasso")
res_ls_ridge_lasso


# Using the entire data, fit Lasso regressions using the lambda grid.
lasso3 <- glmnet(X,Y, alpha=1, lambda=grid)

# Save the estimated 'standardized' coefficients for all 7 predictors without the intercept that is not of interest.
coef_lasso3 <- coef(lasso3)[-1,]
# Transpose the matrix
coef_lasso3_mat <- t(as.matrix(coef_lasso3))
# Rename and sort the matrix by asceding  grid
rownames(coef_lasso3_mat) <- grid
coef_lasso3_mat_sort <- coef_lasso3_mat[order(grid),]

par(mfrow = c(1,1))
# Plot using different colors
matplot(coef_lasso3_mat_sort,type="l",lty=1,xlim=c(0,50),
        xlab="lambda",ylab="coefficient",col=3:9) 
### add legend
legend('bottomright', inset=.005, legend=colnames(coef_lasso3_mat_sort), 
       pch=4, cex=0.6, col=3:9)
# Because of the different magnitudes, some of the predictors are not visible.
# You can separate them in different plots or play with the y-limits.
```

bootstrap怎么interpret？

lasso的意义？？？是用overall dataset还是用cancer_s?
结果怎么interpret 彩色线图？？？

error解决不了:Error in La.svd(x, nu, nv) : 
  BLAS/LAPACK routine 'DLASCL' gave error code -4


